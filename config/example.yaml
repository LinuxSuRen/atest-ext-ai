# Example configuration for atest-ext-ai plugin
# This file demonstrates all available AI service configurations

# Server configuration
server:
  host: "localhost"
  port: 8080
  timeout: "30s"
  max_connections: 100
  socket_path: "/tmp/atest-ext-ai.sock"
  read_timeout: "15s"
  write_timeout: "15s"

# Plugin metadata
plugin:
  name: "atest-ext-ai"
  version: "1.0.0"
  debug: false
  log_level: "info"
  environment: "development"
  metadata:
    description: "AI-powered API testing extension"
    author: "API Testing Team"

# AI Services Configuration
ai:
  # Default service to use when no specific provider is requested
  default_service: "ollama"

  # Fallback order when the default service is unavailable
  fallback_order: ["ollama", "openai", "claude"]

  # Global timeout for AI requests
  timeout: "60s"

  # AI service configurations
  services:
    # Ollama (Local AI) Configuration
    ollama:
      enabled: true
      provider: "ollama"
      # Base URL - can also be set via OLLAMA_BASE_URL environment variable
      endpoint: "http://localhost:11434"
      model: "llama2"
      max_tokens: 4096
      temperature: 0.7
      top_p: 0.9
      priority: 1
      timeout: "60s"
      headers:
        User-Agent: "atest-ext-ai/1.0"
      models:
        - "llama2"
        - "codellama"
        - "mistral"
        - "llama2:13b"

    # OpenAI Configuration
    openai:
      enabled: true
      provider: "openai"
      # API key - can also be set via OPENAI_API_KEY environment variable
      api_key: "${OPENAI_API_KEY}"
      endpoint: "https://api.openai.com/v1"
      model: "gpt-3.5-turbo"
      max_tokens: 4096
      temperature: 0.7
      top_p: 0.9
      priority: 2
      timeout: "30s"
      headers:
        # Organization ID - can also be set via OPENAI_ORG_ID environment variable
        OpenAI-Organization: "${OPENAI_ORG_ID}"
      models:
        - "gpt-3.5-turbo"
        - "gpt-4"
        - "gpt-4-turbo"
        - "gpt-4o"

    # Anthropic Claude Configuration
    claude:
      enabled: true
      provider: "claude"
      # API key - can also be set via ANTHROPIC_API_KEY environment variable
      api_key: "${ANTHROPIC_API_KEY}"
      endpoint: "https://api.anthropic.com"
      model: "claude-3-sonnet-20240229"
      max_tokens: 4096
      temperature: 0.7
      top_p: 0.9
      priority: 3
      timeout: "45s"
      headers:
        anthropic-version: "2023-06-01"
      models:
        - "claude-3-haiku-20240307"
        - "claude-3-sonnet-20240229"
        - "claude-3-opus-20240229"

  # Rate limiting configuration
  rate_limit:
    enabled: true
    requests_per_minute: 60
    burst_size: 10
    window_size: "1m"

  # Circuit breaker configuration
  circuit_breaker:
    enabled: true
    failure_threshold: 5
    success_threshold: 2
    timeout: "60s"
    reset_timeout: "30s"

  # Retry configuration
  retry:
    enabled: true
    max_attempts: 3
    initial_delay: "100ms"
    max_delay: "5s"
    multiplier: 2.0
    jitter: true

  # Cache configuration
  cache:
    enabled: false
    ttl: "1h"
    max_size: 1000
    provider: "memory"
    # redis_url: "redis://localhost:6379"

  # Security configuration
  security:
    encrypt_credentials: true
    allowed_hosts:
      - "localhost"
      - "127.0.0.1"
      - "api.openai.com"
      - "api.anthropic.com"
    tls_enabled: false
    # cert_file: "/path/to/cert.pem"
    # key_file: "/path/to/key.pem"

# Database configuration (optional)
database:
  enabled: false
  driver: "sqlite"
  dsn: "file:atest-ext-ai.db?cache=shared&mode=rwc"
  max_connections: 10
  max_idle: 5
  max_lifetime: "1h"

# Logging configuration
logging:
  level: "info"
  format: "json"
  output: "stdout"
  file:
    path: "/var/log/atest-ext-ai.log"
    max_size: "100MB"
    max_backups: 3
    max_age: 30
    compress: true
  rotation:
    enabled: true
    size: "100MB"
    count: 5
    age: "7d"
    compress: true
  filters:
    - name: "sensitive_data"
      level: "debug"
      pattern: "api_key|password|token"
      fields:
        action: "redact"